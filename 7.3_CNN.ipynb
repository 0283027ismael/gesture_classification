{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c71f1fb1-237e-44ab-9900-d2d20e9bc12f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/25], Loss: 2.8399\n",
      "Epoch [2/25], Loss: 2.7952\n",
      "Epoch [3/25], Loss: 2.6864\n",
      "Epoch [4/25], Loss: 2.5822\n",
      "Epoch [5/25], Loss: 2.4563\n",
      "Epoch [6/25], Loss: 2.3884\n",
      "Epoch [7/25], Loss: 2.3340\n",
      "Epoch [8/25], Loss: 2.2828\n",
      "Epoch [9/25], Loss: 2.2261\n",
      "Epoch [10/25], Loss: 2.1850\n",
      "Epoch [11/25], Loss: 2.1259\n",
      "Epoch [12/25], Loss: 2.0822\n",
      "Epoch [13/25], Loss: 2.0374\n",
      "Epoch [14/25], Loss: 2.0111\n",
      "Epoch [15/25], Loss: 1.9725\n",
      "Epoch [16/25], Loss: 1.9388\n",
      "Epoch [17/25], Loss: 1.8876\n",
      "Epoch [18/25], Loss: 1.8849\n",
      "Epoch [19/25], Loss: 1.8761\n",
      "Epoch [20/25], Loss: 1.8053\n",
      "Epoch [21/25], Loss: 1.7705\n",
      "Epoch [22/25], Loss: 1.7487\n",
      "Epoch [23/25], Loss: 1.7227\n",
      "Epoch [24/25], Loss: 1.6862\n",
      "Epoch [25/25], Loss: 1.6391\n",
      "Accuracy: 34.58%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from scipy import signal\n",
    "import wfdb\n",
    "\n",
    "# Check if CUDA is available and set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 1. Load the Dataset\n",
    "def load_signal(file_path):\n",
    "    # Function to load a single signal file from wfdb\n",
    "    record = wfdb.rdrecord(file_path, sampto=1000)\n",
    "    return record.p_signal\n",
    "\n",
    "def load_dataset(base_path):\n",
    "    signals = []\n",
    "    labels = []\n",
    "    for session in range(1, 4):\n",
    "        for subject in range(1, 44):\n",
    "            session_path = os.path.join(base_path, f'Session{session}/session{session}_participant{subject}')\n",
    "            for gesture in range(1, 18):\n",
    "                for trial in range(1, 8):\n",
    "                    dat_file = f'session{session}_participant{subject}_gesture{gesture}_trial{trial}'\n",
    "                    signal = load_signal(os.path.join(session_path, dat_file))\n",
    "                    signals.append(signal)\n",
    "                    labels.append(gesture)  # Append the gesture label\n",
    "    return np.array(signals), np.array(labels)\n",
    "\n",
    "# 2. Generate Spectrograms\n",
    "def generate_spectrogram(np_signal):\n",
    "    f, t, Sxx = signal.spectrogram(np_signal, fs=2048)  # Adjust fs as per the .hea file\n",
    "    return Sxx\n",
    "\n",
    "def create_spectrograms(signals):\n",
    "    spectrograms = []\n",
    "    for signal in signals:\n",
    "        spec = generate_spectrogram(signal.flatten())\n",
    "        spectrograms.append(spec)\n",
    "    return np.array(spectrograms)\n",
    "\n",
    "# 3. Define the Dataset Class\n",
    "class EMGDataset(Dataset):\n",
    "    def __init__(self, signals, labels):\n",
    "        self.signals = signals\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.signals)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.signals[idx]  # Get the signal\n",
    "        x = torch.tensor(x, dtype=torch.float32)  # Convert to PyTorch tensor\n",
    "        x = x.unsqueeze(0)  # Add a channel dimension: (1, H, W)\n",
    "        x = x.repeat(32, 1, 1)  # Repeat to have 32 channels\n",
    "        y = self.labels[idx] - 1  # Assuming labels are 1-based; convert to 0-based\n",
    "        return x, torch.tensor(y, dtype=torch.long)\n",
    "\n",
    "# 4. Define the TCN Model\n",
    "class TCNModel(nn.Module):\n",
    "    def __init__(self, input_channels, num_classes):\n",
    "        super(TCNModel, self).__init__()\n",
    "        self.tcn = nn.Sequential(\n",
    "            nn.Conv2d(input_channels, 64, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Conv2d(64, 128, kernel_size=(3, 3), padding=(1, 1)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2)),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (input_height // 4) * (input_width // 4), num_classes)  # Adjust according to input size\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.tcn(x)\n",
    "\n",
    "# 5. Set hyperparameters and load data\n",
    "BASE_PATH = '_your_path'  # Update with your dataset path\n",
    "BATCH_SIZE = 4\n",
    "NUM_EPOCHS = 25\n",
    "\n",
    "# Load the dataset\n",
    "signals, labels = load_dataset(BASE_PATH)\n",
    "spectrograms = create_spectrograms(signals)\n",
    "\n",
    "# Create the dataset and dataloaders\n",
    "emg_dataset = EMGDataset(spectrograms, labels)\n",
    "train_size = int(0.8 * len(emg_dataset))\n",
    "test_size = len(emg_dataset) - train_size\n",
    "train_dataset, test_dataset = random_split(emg_dataset, [train_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "# Initialize the model\n",
    "input_channels = 32\n",
    "num_classes = 17  # Adjust based on your specific task\n",
    "\n",
    "input_height, input_width = spectrograms[0].shape  # Get size of the first spectrogram\n",
    "\n",
    "model = TCNModel(input_channels=input_channels, num_classes=num_classes).to(device)\n",
    "\n",
    "# 6. Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# 7. Training Loop\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    model.train()  # Set model to training mode\n",
    "    total_loss = 0\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(inputs)  # Forward pass\n",
    "        loss = criterion(outputs, labels)  # Calculate loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update weights\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{NUM_EPOCHS}], Loss: {total_loss / len(train_loader):.4f}')\n",
    "\n",
    "# 8. Testing Loop\n",
    "model.eval()  # Set model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy * 100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b23c0d6-bfe7-442e-932a-d4ee1e976b75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
